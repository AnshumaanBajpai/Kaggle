{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outbrain Click Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This note books contains overall information and a summary of all the data that we have for the kaggle competition https://www.kaggle.com/c/outbrain-click-prediction. It goes through each of the files and presents the overall summay of the data. The analysis is done using Pyspark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) File Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Location of all the files.\n",
    "# These files are located in google cloud platform\n",
    "clTe = \"gs://jupyterbucket/outbrainData/clicks_test.csv\"\n",
    "clTr = \"gs://jupyterbucket/outbrainData/clicks_train.csv\"\n",
    "docCat = \"gs://jupyterbucket/outbrainData/documents_categories.csv\"\n",
    "docEnt = \"gs://jupyterbucket/outbrainData/documents_entities.csv\"\n",
    "docMet = \"gs://jupyterbucket/outbrainData/documents_meta.csv\"\n",
    "docTop = \"gs://jupyterbucket/outbrainData/documents_topics.csv\"\n",
    "evt = \"gs://jupyterbucket/outbrainData/events.csv\"\n",
    "pageViewsSam = \"gs://jupyterbucket/outbrainData/page_views_sample.csv\"\n",
    "pageViews = \"gs://jupyterbucket/outbrainData/page_views.csv\"\n",
    "proCon = \"gs://jupyterbucket/outbrainData/promoted_content.csv\"\n",
    "samSub = \"gs://jupyterbucket/outbrainData/sample_submission.csv\"\n",
    "\n",
    "# Creating a list to iterate over in case we need to perform some operation for all the csv files\n",
    "allFiles = [clTe, clTr, docCat, docEnt, docMet, docTop, evt, pageViewsSam, proCon, samSub, pageViews]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Funtion to get an overview of each datafile\n",
    "* Obtain a basic understanding of the file in terms of number of columns\n",
    "* Generate Schema for each of the files that will be used later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def csvOverview(fpath):\n",
    "    '''\n",
    "    Function presents a basic overview of the file fed in the argument\n",
    "    @params\n",
    "    fpath: Path to the csv file that needs to be analyzed\n",
    "    @returns \n",
    "    None\n",
    "    '''\n",
    "    # Reading the data as a spark dataframe\n",
    "    print fpath.split(\"/\")[-1]\n",
    "    fpathDF = spark.read.options(header='true', inferschema='true', nullValue='\\\\N') \\\n",
    "                .csv(fpath)\n",
    "    print \"Dataframe has \", fpathDF.count(), \" rows.\"\n",
    "    fpathDF.show(n=5)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Displaying all the files and generating Schema for each"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) page_views.csv and page_views_sample.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_views_sample.csv\n",
      "Dataframe has  9999999  rows.\n",
      "+--------------+-----------+---------+--------+------------+--------------+\n",
      "|          uuid|document_id|timestamp|platform|geo_location|traffic_source|\n",
      "+--------------+-----------+---------+--------+------------+--------------+\n",
      "|1fd5f051fba643|        120| 31905835|       1|          RS|             2|\n",
      "|8557aa9004be3b|        120| 32053104|       1|       VN>44|             2|\n",
      "|c351b277a358f0|        120| 54013023|       1|       KR>12|             1|\n",
      "|8205775c5387f9|        120| 44196592|       1|       IN>16|             2|\n",
      "|9cb0ccd8458371|        120| 65817371|       1|   US>CA>807|             2|\n",
      "+--------------+-----------+---------+--------+------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csvOverview(pageViewsSam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining the Schema for the above files\n",
    "pageViewsSamSchema = StructType(\n",
    "                    [StructField(\"uuid\", StringType(), True),\n",
    "                     StructField(\"document_id\", StringType(), True),\n",
    "                     StructField(\"timestamp\", IntegerType(), True),\n",
    "                     StructField(\"platform\", StringType(), True),\n",
    "                     StructField(\"geo_location\", StringType(), True),\n",
    "                     StructField(\"traffic_source\", StringType(), True)])\n",
    "pageViewsSchema = StructType(\n",
    "                    [StructField(\"uuid\", StringType(), True),\n",
    "                     StructField(\"document_id\", StringType(), True),\n",
    "                     StructField(\"timestamp\", IntegerType(), True),\n",
    "                     StructField(\"platform\", StringType(), True),\n",
    "                     StructField(\"geo_location\", StringType(), True),\n",
    "                     StructField(\"traffic_source\", StringType(), True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The columns in the file are as follows\n",
    "* uuid: Unique User Id. uuid represents a unique user\n",
    "* document_id: Represent a unique web page that the user visited\n",
    "* timestamp: time in ms since Jan 1, 1970 - 1465876799998\n",
    "* platform: Represents whether the document was viewed on desktop(1), mobile(2) or tablet(3)\n",
    "* geo_location: Location where the ad was viewed\n",
    "* traffic source: Specifies how the user reached this document: Internal(1), Search(2) or Social(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) clicks_train.csv and clicks_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clicks_train.csv\n",
      "Dataframe has  87141731  rows.\n",
      "+----------+------+-------+\n",
      "|display_id| ad_id|clicked|\n",
      "+----------+------+-------+\n",
      "|         1| 42337|      0|\n",
      "|         1|139684|      0|\n",
      "|         1|144739|      1|\n",
      "|         1|156824|      0|\n",
      "|         1|279295|      0|\n",
      "+----------+------+-------+\n",
      "only showing top 5 rows\n",
      "\n",
      "clicks_test.csv\n",
      "Dataframe has  32225162  rows.\n",
      "+----------+------+\n",
      "|display_id| ad_id|\n",
      "+----------+------+\n",
      "|  16874594| 66758|\n",
      "|  16874594|150083|\n",
      "|  16874594|162754|\n",
      "|  16874594|170392|\n",
      "|  16874594|172888|\n",
      "+----------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csvOverview(clTr)\n",
    "csvOverview(clTe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clTeSchema = StructType(\n",
    "                    [StructField(\"display_id\", StringType(), True),\n",
    "                     StructField(\"ad_id\", StringType(), True)])\n",
    "clTrSchema = StructType(\n",
    "                    [StructField(\"display_id\", StringType(), True),\n",
    "                     StructField(\"ad_id\", StringType(), True),\n",
    "                     StructField(\"clicked\", IntegerType(), True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The columns mentioned above are\n",
    "* display_id: Represent a set of ads which are displayed on a page at a given time. Either none or one of these are clicked and corresponds to a specific user, specific page and so on\n",
    "* ad_id: Id for a given ad\n",
    "* clicked: Representing whether an ad was clicked or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|display_id|count|\n",
      "+----------+-----+\n",
      "|  18355686|   12|\n",
      "|  19745750|   12|\n",
      "|  18555755|   12|\n",
      "|  18701552|   12|\n",
      "|  19389874|   12|\n",
      "+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "Number of distinct display_ids: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6245533"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We perform some basic analysis on clicks_test.csv and clicks_train.csv\n",
    "clTe_DF = spark.read.schema(clTeSchema).options(header='true', inferschema='false', nullValue='\\\\N').csv(clTe)\n",
    "clTe_DF_Gby_display = clTe_DF.groupBy('display_id').count().sort(F.col(\"count\").desc())\n",
    "clTe_DF_Gby_display.show(n=5)\n",
    "print \"Number of distinct display_ids: \"\n",
    "clTe_DF_Gby_display.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we look at the data in clicks_train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+\n",
      "| ad_id|avg(clicked)|\n",
      "+------+------------+\n",
      "|302973|         1.0|\n",
      "|447127|         1.0|\n",
      "|325026|         1.0|\n",
      "|310550|         1.0|\n",
      "|275679|         1.0|\n",
      "+------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We perform some basic analysis on clicks_test.csv and clicks_train.csv\n",
    "clTr_DF = spark.read.schema(clTrSchema).options(header='true', inferschema='false', nullValue='\\\\N').csv(clTr)\n",
    "clTr_DF_Gby_display = clTr_DF.groupBy('ad_id').avg('clicked').sort(F.col(\"avg(clicked)\").desc())\n",
    "clTr_DF_Gby_display.show(n=5)\n",
    "#print \"Number of distinct display_ids: \"\n",
    "#clTe_DF_Gby_display.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) events.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "events.csv\n",
      "Dataframe has  23120126  rows.\n",
      "+----------+--------------+-----------+---------+--------+------------+\n",
      "|display_id|          uuid|document_id|timestamp|platform|geo_location|\n",
      "+----------+--------------+-----------+---------+--------+------------+\n",
      "|         1|cb8c55702adb93|     379743|       61|       3|   US>SC>519|\n",
      "|         2|79a85fa78311b9|    1794259|       81|       2|   US>CA>807|\n",
      "|         3|822932ce3d8757|    1179111|      182|       2|   US>MI>505|\n",
      "|         4|85281d0a49f7ac|    1777797|      234|       2|   US>WV>564|\n",
      "|         5|8d0daef4bf5b56|     252458|      338|       2|       SG>00|\n",
      "+----------+--------------+-----------+---------+--------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csvOverview(evt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evtSchema = StructType(\n",
    "                    [StructField(\"display_id\", StringType(), True),\n",
    "                     StructField(\"uuid\", StringType(), True),\n",
    "                     StructField(\"document_id\", StringType(), True),\n",
    "                     StructField(\"timestamp\", IntegerType(), True),\n",
    "                     StructField(\"platform\", StringType(), True),\n",
    "                     StructField(\"geo_location\", StringType(), True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) promoted_content.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "promoted_content.csv\n",
      "Dataframe has  559583  rows.\n",
      "+-----+-----------+-----------+-------------+\n",
      "|ad_id|document_id|campaign_id|advertiser_id|\n",
      "+-----+-----------+-----------+-------------+\n",
      "|    1|       6614|          1|            7|\n",
      "|    2|     471467|          2|            7|\n",
      "|    3|       7692|          3|            7|\n",
      "|    4|     471471|          2|            7|\n",
      "|    5|     471472|          2|            7|\n",
      "+-----+-----------+-----------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csvOverview(proCon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proConSchema = StructType(\n",
    "                    [StructField(\"ad_id\", StringType(), True),\n",
    "                     StructField(\"document_id\", StringType(), True),\n",
    "                     StructField(\"campaign_id\", StringType(), True),\n",
    "                     StructField(\"advertiser_id\", StringType(), True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional column information\n",
    "* campaign_id: Each ad belongs to a particular campaign and this id refers to a specific campaign\n",
    "* advertiser_id: Refers to a specific advertiser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e) documents_meta.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "documents_meta.csv\n",
      "Dataframe has  2999334  rows.\n",
      "+-----------+---------+------------+--------------------+\n",
      "|document_id|source_id|publisher_id|        publish_time|\n",
      "+-----------+---------+------------+--------------------+\n",
      "|    1595802|        1|         603|2016-06-05 00:00:...|\n",
      "|    1524246|        1|         603|2016-05-26 11:00:...|\n",
      "|    1617787|        1|         603|2016-05-27 00:00:...|\n",
      "|    1615583|        1|         603|2016-06-07 00:00:...|\n",
      "|    1615460|        1|         603|2016-06-20 00:00:...|\n",
      "+-----------+---------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csvOverview(docMet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docMetSchema = StructType(\n",
    "                    [StructField(\"document_id\", StringType(), True),\n",
    "                     StructField(\"source_id\", StringType(), True),\n",
    "                     StructField(\"publisher_id\", StringType(), True),\n",
    "                     StructField(\"publish_time\", StringType(), True)])\n",
    "# This publish time could be assigned the DateType()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional column information\n",
    "* source_id: Something like editor.cnn.com which is the websource on which the document is available\n",
    "* publisher_id: Something like cnn.com\n",
    "* publish_time: The time at which the document was published"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f) documents_categories.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "documents_categories.csv\n",
      "Dataframe has  5481475  rows.\n",
      "+-----------+-----------+----------------+\n",
      "|document_id|category_id|confidence_level|\n",
      "+-----------+-----------+----------------+\n",
      "|    1595802|       1611|            0.92|\n",
      "|    1595802|       1610|            0.07|\n",
      "|    1524246|       1807|            0.92|\n",
      "|    1524246|       1608|            0.07|\n",
      "|    1617787|       1807|            0.92|\n",
      "+-----------+-----------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csvOverview(docCat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docCatSchema = StructType(\n",
    "                    [StructField(\"document_id\", StringType(), True),\n",
    "                     StructField(\"category_id\", StringType(), True),\n",
    "                     StructField(\"confidence_level\", DoubleType(), True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Information about the columns\n",
    "* category_id: Each document belongs to a specific category\n",
    "* confidence_level: Represents the probability that the given document belongs to this category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### g) document_entities.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "documents_entities.csv\n",
      "Dataframe has  5537552  rows.\n",
      "+-----------+--------------------+-----------------+\n",
      "|document_id|           entity_id| confidence_level|\n",
      "+-----------+--------------------+-----------------+\n",
      "|    1524246|f9eec25663db4cd83...|0.672865314504701|\n",
      "|    1524246|55ebcfbdaff1d6f60...|0.399113728441297|\n",
      "|    1524246|839907a972930b17b...|0.392095749652966|\n",
      "|    1524246|04d8f9a1ad48f126d...|0.213996376305138|\n",
      "|    1617787|612a1d17685a498af...|0.386192829940441|\n",
      "+-----------+--------------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csvOverview(docEnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docEntSchema = StructType(\n",
    "                    [StructField(\"document_id\", StringType(), True),\n",
    "                     StructField(\"entity_id\", StringType(), True),\n",
    "                     StructField(\"confidence_level\", DoubleType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1791420"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpathEntDF = spark.read.schema(docEntSchema).options(header='true', inferschema='true', nullValue='\\\\N').csv(docEnt)\n",
    "fpathEntDF.select('document_id').distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Information about the columns\n",
    "* entity_id: An entity (person, organization or location) featured in a document\n",
    "* confidence_level: Represents the probability that the given entity is present in the document category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### h) document_topics.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "documents_topics.csv\n",
      "Dataframe has  11325960  rows.\n",
      "+-----------+--------+------------------+\n",
      "|document_id|topic_id|  confidence_level|\n",
      "+-----------+--------+------------------+\n",
      "|    1595802|     140|0.0731131601068925|\n",
      "|    1595802|      16|0.0594164867373976|\n",
      "|    1595802|     143|0.0454207537554526|\n",
      "|    1595802|     170|0.0388674285182961|\n",
      "|    1524246|     113| 0.196450402209685|\n",
      "+-----------+--------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csvOverview(docTop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docTopSchema = StructType(\n",
    "                    [StructField(\"document_id\", StringType(), True),\n",
    "                     StructField(\"topic_id\", StringType(), True),\n",
    "                     StructField(\"confidence_level\", DoubleType(), True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i) This is how submission is supposed to look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission.csv\n",
      "Dataframe has  6245533  rows.\n",
      "+----------+--------------------+\n",
      "|display_id|               ad_id|\n",
      "+----------+--------------------+\n",
      "|  16874594|66758 150083 1627...|\n",
      "|  16874595|   8846 30609 143982|\n",
      "|  16874596|11430 57197 13282...|\n",
      "|  16874597|137858 143981 155...|\n",
      "|  16874598|67292 145937 2500...|\n",
      "+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csvOverview(samSub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
